# molsim-ml-code-examples
Code examples used in the ML course of the MolSim winterschool


## Contents 

- [importance-of-invariance](./importance-of-invariance/) gives a basic example of why it is important to encode molecular geometries in a translationally/permutationally/rotationally invariant fashion.
- [lr-gradient-descent](./lr-gradient-descent/) implements linear regression using gradient descent using Jax
- [bias-variance-tradeoff](./bias-variance-tradeoff/) shows some examples of under/overfitting and the utility of incorporating prior knowledge 


## Notes 

- If you are using this in class, remember to turn Copilot off, as it will directly will in all the code and give you no time to ask students for ideas.
- If you are running on battery, some of the operations can be slow if you use battery saver mode
## Acknowledgments

- The content on gradient descent is very inspired by Andrey Karparthy's content:
  - [A Hacker's guide to Neural Nets](http://karpathy.github.io/neuralnets/)
  - [Neural Networks: Zero to Hero](https://karpathy.ai/zero-to-hero.html)

  and by [Andrew White's book](https://github.com/whitead/dmol-book).